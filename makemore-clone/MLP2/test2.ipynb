{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, fan_in, fan_out, bias=True, device=\"cpu\"):\n",
    "        self.weight = torch.randn((fan_in, fan_out), device=device) / fan_in**0.5\n",
    "        self.bias = torch.zeros(fan_out, device=device) if bias else None\n",
    "    def __call__(self,X):\n",
    "        self.out = X @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([self.bias] if self.bias is not None else [])\n",
    "\n",
    "class BatchNorm1d():\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.001, device=\"cpu\"):\n",
    "        self.gamma = torch.ones((1,dim), device=device)\n",
    "        self.beta = torch.zeros((1,dim), device=device)\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.running_mean = torch.zeros((1,dim), device=device)\n",
    "        self.running_var = torch.ones((1,dim), device=device)\n",
    "        self.training = True\n",
    "    def __call__(self, X):\n",
    "        if self.training:\n",
    "            with torch.inference_mode():\n",
    "                mean = X.mean(0, keepdim=True)\n",
    "                var = X.var(0, keepdim=True)\n",
    "                self.running_mean = (1-self.momentum) * self.running_mean + self.momentum * mean\n",
    "                self.running_var = (1-self.momentum) * self.running_var + self.momentum * var\n",
    "        else:\n",
    "            mean = self.running_mean\n",
    "            var = self.running_var\n",
    "        return self.gamma * (X - mean) / (torch.sqrt(var)+self.eps) + self.beta\n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "class Embedding():\n",
    "    def __init__(self, num_embeddings, dim, device=\"cpu\"):\n",
    "        self.weight = torch.randn((num_embeddings, dim), device=device)\n",
    "    def __call__(self, ix):\n",
    "        self.out = self.weight[ix]\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return [self.weight]\n",
    "\n",
    "class Flatten():\n",
    "    def __call__(self, X):\n",
    "        self.out = X.reshape(X.shape[0],-1)\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "class Tanh():\n",
    "    def __call__(self, X):\n",
    "        self.out = torch.tanh(X)\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "class Sequential():\n",
    "    def __init__(self, layers=[]):\n",
    "        self.layers=layers\n",
    "    def __call__(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('params/model.pt')\n",
    "chars = pickle.load(open('params/chars.pkl', 'rb'))\n",
    "char_index = pickle.load(open('params/char_index.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(prev_8):\n",
    "    prev_8 = torch.tensor(prev_8).reshape(1,8).to(device)\n",
    "    probs = torch.softmax(model(prev_8), dim=1)\n",
    "    return chars[torch.multinomial(probs, 1).item()]\n",
    "def get_name():\n",
    "    name = ''\n",
    "    prev_8 = [0,0,0,0,0,0,0,0]\n",
    "    next = next_char(prev_8)\n",
    "    while next != '!':\n",
    "        name += next\n",
    "        prev_8 = prev_8[1:] + [char_index[next]]\n",
    "        next = next_char(prev_8)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "magirathi\n",
      "indravasaha\n",
      "dharshini\n",
      "amitiika\n",
      "anruthan\n",
      "banaka\n",
      "anavinana\n",
      "eyaankar\n",
      "kishwata\n",
      "nirjety\n",
      "varishan\n",
      "prasinipan\n",
      "kalavan\n",
      "sreethavendux\n",
      "yukisney\n",
      "bhashvini\n",
      "jalais\n",
      "anil\n",
      "yesuthayan\n",
      "nirmipa\n",
      "ashuka\n",
      "irangaj\n",
      "mahasidha\n",
      "avallika\n",
      "bhasukhan\n",
      "niresh\n",
      "roshii\n",
      "nalini\n",
      "vanesha\n",
      "thuvena\n",
      "aamil\n",
      "mayamesh\n",
      "krishna\n",
      "manavayuha\n",
      "hrishyan\n",
      "kavinan\n",
      "binani\n",
      "jeyasha\n",
      "yaveenan\n",
      "chayuth\n",
      "lovan\n",
      "jeeyani\n",
      "legasha\n",
      "kaleshwen\n",
      "kalishree\n",
      "eyallikan\n",
      "anuriva\n",
      "pamanya\n",
      "ibhkuyan\n",
      "nerudheep\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(get_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalised_negative_log_likelihood(word):\n",
    "    prev_8 = torch.tensor([0,0,0,0,0,0,0,0]).reshape(1,8).to(device)\n",
    "    nll = 0\n",
    "    for c in word:\n",
    "        probs = torch.softmax(model(prev_8), dim=1)\n",
    "        nll += -torch.log(probs[:,char_index[c]])\n",
    "        prev_8 = torch.cat((prev_8[:,1:], torch.tensor([char_index[c]]).reshape(1,1).to(device)), dim=1)\n",
    "    return nll / len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.286522626876831, 3.1762070655822754)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_normalised_negative_log_likelihood('arjun').item(), get_normalised_negative_log_likelihood('steve').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11f35b3a2c2f9db604914e925818b5f3881c103430a3a0a48ead856bc8f67805"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
